{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04077967",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-20 17:00:56.303032: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-20 17:00:57.805946: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI AVX_VNNI_INT8 AVX_NE_CONVERT FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-20 17:01:23.507943: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1758412897.929369  154313 gpu_device.cc:2431] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 12.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.\n"
     ]
    }
   ],
   "source": [
    "#import pandas as pd \n",
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbf3b41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e0f28bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello ese\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello ese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ca24e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.3\n",
      "Numpy 2.2.6\n",
      "TensorFlow 2.20.0\n"
     ]
    }
   ],
   "source": [
    "!python --version\n",
    "print('Numpy ' + np.__version__)\n",
    "print('TensorFlow ' + tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e02bb7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cu128\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1427fcdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f05191fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CNNBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 4, stride, bias=False, padding_mode=\"reflect\"), \n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2), \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels=3, features=[64, 128, 256, 512]): \n",
    "        super().__init__()\n",
    "        self.initial = nn.Sequential(\n",
    "            nn.Conv2d(in_channels*2, features[0], kernel_size=4, stride=2, padding=1, padding_mode=\"reflect\"),\n",
    "            nn.LeakyReLU(0.2),  \n",
    "        )\n",
    "\n",
    "        layers = []\n",
    "        in_channels = features[0]\n",
    "        for feature in features[1:]:\n",
    "            layers.append(\n",
    "                CNNBlock(in_channels, feature, stride=1 if feature == features[-1] else 2),\n",
    "            ) \n",
    "            in_channels = feature\n",
    "\n",
    "        \n",
    "        layers.append(\n",
    "            nn.Conv2d(\n",
    "                in_channels, 1, kernel_size=4, stride=1, padding=1, padding_mode=\"reflect\"\n",
    "            ),\n",
    "        )\n",
    "\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, y): \n",
    "        x = torch.cat([x, y], dim=1)\n",
    "        x = self.initial(x)\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4243c95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    x = torch.randn((1, 3, 256, 256))\n",
    "    y = torch.randn((1, 3, 256, 256))\n",
    "    model = Discriminator()\n",
    "    preds = model(x, y)\n",
    "    print(preds.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87ef47cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 26, 26])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "944e52cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb0dd681",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, down=True, act=\"relu\", use_dropout=False):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 4, 2, 1, bias=False, padding_mode=\"reflect\")\n",
    "            if down \n",
    "            else nn.ConvTranspose2d(in_channels, out_channels, 4, 2, 1, bias = False), \n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU() if act == \"relu\" else nn.LeakyReLU(0.2), \n",
    "\n",
    "        )\n",
    "        self.use_dropout = use_dropout\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return self.dropout(x) if self.use_dropout else x \n",
    "    \n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, in_channels = 3, features=64): \n",
    "        super().__init__()   \n",
    "        self.initial_down = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, features, 4, 2, 1, padding_mode=\"reflect\"),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "        ) #128 after this one \n",
    "\n",
    "        self.down1 = Block(features, features*2, down=True, act=\"leaky\", use_dropout=False )    #64x64 \n",
    "        self.down2 = Block(features*2, features*4, down=True, act=\"leaky\", use_dropout=False )  #32x32 \n",
    "        self.down3 = Block(features*4, features*8, down=True, act=\"leaky\", use_dropout=False )  #16\n",
    "        self.down4 = Block(features*8, features*8, down=True, act=\"leaky\", use_dropout=False )  #8\n",
    "        self.down5 = Block(features*8, features*8, down=True, act=\"leaky\", use_dropout=False )  #4 \n",
    "        self.down6 = Block(features*8, features*8, down=True, act=\"leaky\", use_dropout=False )  #2\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(features*8, features*8, 4, 2, 1, padding_mode=\"reflect\"), nn.ReLU(), #1x1\n",
    "        )\n",
    "        self.up1 = Block(features*8, features*8, down=False, act=\"relu\", use_dropout=True) #2x2  \n",
    "        self.up2 = Block(features*8*2, features*8, down=False, act=\"relu\", use_dropout=True) #4x4\n",
    "        self.up3 = Block(features*8*2, features*8, down=False, act=\"relu\", use_dropout=True) #8x8\n",
    "        self.up4 = Block(features*8*2, features*8, down=False, act=\"relu\", use_dropout=False) #16x16\n",
    "        self.up5 = Block(features*8*2, features*4, down=False, act=\"relu\", use_dropout=False) #32x32\n",
    "        self.up6 = Block(features*4*2, features*2, down=False, act=\"relu\", use_dropout=False) #64x64\n",
    "        self.up7 = Block(features*2*2, features, down=False, act=\"relu\", use_dropout=False) #128x128\n",
    "        self.final_up = nn.Sequential(\n",
    "            nn.ConvTranspose2d(features*2, in_channels, kernel_size=4, stride=2, padding=1), \n",
    "            nn.Tanh(),  #256x256\n",
    "        )\n",
    "\n",
    "    def forward(self, x): \n",
    "        d1 = self.initial_down(x) #128x128 \n",
    "        d2 = self.down1(d1)     #64x64  \n",
    "        d3 = self.down2(d2)     #32x32 \n",
    "        d4 = self.down3(d3)     #16x16\n",
    "        d5 = self.down4(d4)     #8x8\n",
    "        d6 = self.down5(d5)     #4x4\n",
    "        d7 = self.down6(d6)     #2x2\n",
    "        bottleneck = self.bottleneck(d7) #1x1\n",
    "        up1 = self.up1(bottleneck)      #2x2\n",
    "        up2 = self.up2(torch.cat([up1, d7], 1)) #4x4\n",
    "        up3 = self.up3(torch.cat([up2, d6], 1)) #8x8\n",
    "        up4 = self.up4(torch.cat([up3, d5], 1)) #16x16\n",
    "        up5 = self.up5(torch.cat([up4, d4], 1)) #32x32\n",
    "        up6 = self.up6(torch.cat([up5, d3], 1)) #64x64\n",
    "        up7 = self.up7(torch.cat([up6, d2], 1)) #128x128\n",
    "        \n",
    "        return self.final_up(torch.cat([up7, d1 ], 1)) #256x256 \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8190872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test1(): \n",
    "    x = torch.randn((1, 3, 256, 256))\n",
    "    model = Generator(in_channels=3, features=64)\n",
    "    preds= model(x)\n",
    "    print(preds.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b12af3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    test1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6462edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################ \n",
    "#####Config.py \n",
    "\n",
    "\n",
    "\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8202600e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#######################################################################################################################################\n",
    "#Implement DATAset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94baef71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image \n",
    "import numpy as np \n",
    "import os \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.utils import save_image \n",
    "import sys \n",
    "\n",
    "import config \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7aead3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1.jpg', '10.jpg', '100.jpg', '1000.jpg', '1001.jpg', '1002.jpg', '1003.jpg', '1004.jpg', '1005.jpg', '1006.jpg', '1007.jpg', '1008.jpg', '1009.jpg', '101.jpg', '1010.jpg', '1011.jpg', '1012.jpg', '1013.jpg', '1014.jpg', '1015.jpg', '1016.jpg', '1017.jpg', '1018.jpg', '1019.jpg', '102.jpg', '1020.jpg', '1021.jpg', '1022.jpg', '1023.jpg', '1024.jpg', '1025.jpg', '1026.jpg', '1027.jpg', '1028.jpg', '1029.jpg', '103.jpg', '1030.jpg', '1031.jpg', '1032.jpg', '1033.jpg', '1034.jpg', '1035.jpg', '1036.jpg', '1037.jpg', '1038.jpg', '1039.jpg', '104.jpg', '1040.jpg', '1041.jpg', '1042.jpg', '1043.jpg', '1044.jpg', '1045.jpg', '1046.jpg', '1047.jpg', '1048.jpg', '1049.jpg', '105.jpg', '1050.jpg', '1051.jpg', '1052.jpg', '1053.jpg', '1054.jpg', '1055.jpg', '1056.jpg', '1057.jpg', '1058.jpg', '1059.jpg', '106.jpg', '1060.jpg', '1061.jpg', '1062.jpg', '1063.jpg', '1064.jpg', '1065.jpg', '1066.jpg', '1067.jpg', '1068.jpg', '1069.jpg', '107.jpg', '1070.jpg', '1071.jpg', '1072.jpg', '1073.jpg', '1074.jpg', '1075.jpg', '1076.jpg', '1077.jpg', '1078.jpg', '1079.jpg', '108.jpg', '1080.jpg', '1081.jpg', '1082.jpg', '1083.jpg', '1084.jpg', '1085.jpg', '1086.jpg', '1087.jpg', '1088.jpg', '1089.jpg', '109.jpg', '1090.jpg', '1091.jpg', '1092.jpg', '1093.jpg', '1094.jpg', '1095.jpg', '1096.jpg', '11.jpg', '110.jpg', '111.jpg', '112.jpg', '113.jpg', '114.jpg', '115.jpg', '116.jpg', '117.jpg', '118.jpg', '119.jpg', '12.jpg', '120.jpg', '121.jpg', '122.jpg', '123.jpg', '124.jpg', '125.jpg', '126.jpg', '127.jpg', '128.jpg', '129.jpg', '13.jpg', '130.jpg', '131.jpg', '132.jpg', '133.jpg', '134.jpg', '135.jpg', '136.jpg', '137.jpg', '138.jpg', '139.jpg', '14.jpg', '140.jpg', '141.jpg', '142.jpg', '143.jpg', '144.jpg', '145.jpg', '146.jpg', '147.jpg', '148.jpg', '149.jpg', '15.jpg', '150.jpg', '151.jpg', '152.jpg', '153.jpg', '154.jpg', '155.jpg', '156.jpg', '157.jpg', '158.jpg', '159.jpg', '16.jpg', '160.jpg', '161.jpg', '162.jpg', '163.jpg', '164.jpg', '165.jpg', '166.jpg', '167.jpg', '168.jpg', '169.jpg', '17.jpg', '170.jpg', '171.jpg', '172.jpg', '173.jpg', '174.jpg', '175.jpg', '176.jpg', '177.jpg', '178.jpg', '179.jpg', '18.jpg', '180.jpg', '181.jpg', '182.jpg', '183.jpg', '184.jpg', '185.jpg', '186.jpg', '187.jpg', '188.jpg', '189.jpg', '19.jpg', '190.jpg', '191.jpg', '192.jpg', '193.jpg', '194.jpg', '195.jpg', '196.jpg', '197.jpg', '198.jpg', '199.jpg', '2.jpg', '20.jpg', '200.jpg', '201.jpg', '202.jpg', '203.jpg', '204.jpg', '205.jpg', '206.jpg', '207.jpg', '208.jpg', '209.jpg', '21.jpg', '210.jpg', '211.jpg', '212.jpg', '213.jpg', '214.jpg', '215.jpg', '216.jpg', '217.jpg', '218.jpg', '219.jpg', '22.jpg', '220.jpg', '221.jpg', '222.jpg', '223.jpg', '224.jpg', '225.jpg', '226.jpg', '227.jpg', '228.jpg', '229.jpg', '23.jpg', '230.jpg', '231.jpg', '232.jpg', '233.jpg', '234.jpg', '235.jpg', '236.jpg', '237.jpg', '238.jpg', '239.jpg', '24.jpg', '240.jpg', '241.jpg', '242.jpg', '243.jpg', '244.jpg', '245.jpg', '246.jpg', '247.jpg', '248.jpg', '249.jpg', '25.jpg', '250.jpg', '251.jpg', '252.jpg', '253.jpg', '254.jpg', '255.jpg', '256.jpg', '257.jpg', '258.jpg', '259.jpg', '26.jpg', '260.jpg', '261.jpg', '262.jpg', '263.jpg', '264.jpg', '265.jpg', '266.jpg', '267.jpg', '268.jpg', '269.jpg', '27.jpg', '270.jpg', '271.jpg', '272.jpg', '273.jpg', '274.jpg', '275.jpg', '276.jpg', '277.jpg', '278.jpg', '279.jpg', '28.jpg', '280.jpg', '281.jpg', '282.jpg', '283.jpg', '284.jpg', '285.jpg', '286.jpg', '287.jpg', '288.jpg', '289.jpg', '29.jpg', '290.jpg', '291.jpg', '292.jpg', '293.jpg', '294.jpg', '295.jpg', '296.jpg', '297.jpg', '298.jpg', '299.jpg', '3.jpg', '30.jpg', '300.jpg', '301.jpg', '302.jpg', '303.jpg', '304.jpg', '305.jpg', '306.jpg', '307.jpg', '308.jpg', '309.jpg', '31.jpg', '310.jpg', '311.jpg', '312.jpg', '313.jpg', '314.jpg', '315.jpg', '316.jpg', '317.jpg', '318.jpg', '319.jpg', '32.jpg', '320.jpg', '321.jpg', '322.jpg', '323.jpg', '324.jpg', '325.jpg', '326.jpg', '327.jpg', '328.jpg', '329.jpg', '33.jpg', '330.jpg', '331.jpg', '332.jpg', '333.jpg', '334.jpg', '335.jpg', '336.jpg', '337.jpg', '338.jpg', '339.jpg', '34.jpg', '340.jpg', '341.jpg', '342.jpg', '343.jpg', '344.jpg', '345.jpg', '346.jpg', '347.jpg', '348.jpg', '349.jpg', '35.jpg', '350.jpg', '351.jpg', '352.jpg', '353.jpg', '354.jpg', '355.jpg', '356.jpg', '357.jpg', '358.jpg', '359.jpg', '36.jpg', '360.jpg', '361.jpg', '362.jpg', '363.jpg', '364.jpg', '365.jpg', '366.jpg', '367.jpg', '368.jpg', '369.jpg', '37.jpg', '370.jpg', '371.jpg', '372.jpg', '373.jpg', '374.jpg', '375.jpg', '376.jpg', '377.jpg', '378.jpg', '379.jpg', '38.jpg', '380.jpg', '381.jpg', '382.jpg', '383.jpg', '384.jpg', '385.jpg', '386.jpg', '387.jpg', '388.jpg', '389.jpg', '39.jpg', '390.jpg', '391.jpg', '392.jpg', '393.jpg', '394.jpg', '395.jpg', '396.jpg', '397.jpg', '398.jpg', '399.jpg', '4.jpg', '40.jpg', '400.jpg', '401.jpg', '402.jpg', '403.jpg', '404.jpg', '405.jpg', '406.jpg', '407.jpg', '408.jpg', '409.jpg', '41.jpg', '410.jpg', '411.jpg', '412.jpg', '413.jpg', '414.jpg', '415.jpg', '416.jpg', '417.jpg', '418.jpg', '419.jpg', '42.jpg', '420.jpg', '421.jpg', '422.jpg', '423.jpg', '424.jpg', '425.jpg', '426.jpg', '427.jpg', '428.jpg', '429.jpg', '43.jpg', '430.jpg', '431.jpg', '432.jpg', '433.jpg', '434.jpg', '435.jpg', '436.jpg', '437.jpg', '438.jpg', '439.jpg', '44.jpg', '440.jpg', '441.jpg', '442.jpg', '443.jpg', '444.jpg', '445.jpg', '446.jpg', '447.jpg', '448.jpg', '449.jpg', '45.jpg', '450.jpg', '451.jpg', '452.jpg', '453.jpg', '454.jpg', '455.jpg', '456.jpg', '457.jpg', '458.jpg', '459.jpg', '46.jpg', '460.jpg', '461.jpg', '462.jpg', '463.jpg', '464.jpg', '465.jpg', '466.jpg', '467.jpg', '468.jpg', '469.jpg', '47.jpg', '470.jpg', '471.jpg', '472.jpg', '473.jpg', '474.jpg', '475.jpg', '476.jpg', '477.jpg', '478.jpg', '479.jpg', '48.jpg', '480.jpg', '481.jpg', '482.jpg', '483.jpg', '484.jpg', '485.jpg', '486.jpg', '487.jpg', '488.jpg', '489.jpg', '49.jpg', '490.jpg', '491.jpg', '492.jpg', '493.jpg', '494.jpg', '495.jpg', '496.jpg', '497.jpg', '498.jpg', '499.jpg', '5.jpg', '50.jpg', '500.jpg', '501.jpg', '502.jpg', '503.jpg', '504.jpg', '505.jpg', '506.jpg', '507.jpg', '508.jpg', '509.jpg', '51.jpg', '510.jpg', '511.jpg', '512.jpg', '513.jpg', '514.jpg', '515.jpg', '516.jpg', '517.jpg', '518.jpg', '519.jpg', '52.jpg', '520.jpg', '521.jpg', '522.jpg', '523.jpg', '524.jpg', '525.jpg', '526.jpg', '527.jpg', '528.jpg', '529.jpg', '53.jpg', '530.jpg', '531.jpg', '532.jpg', '533.jpg', '534.jpg', '535.jpg', '536.jpg', '537.jpg', '538.jpg', '539.jpg', '54.jpg', '540.jpg', '541.jpg', '542.jpg', '543.jpg', '544.jpg', '545.jpg', '546.jpg', '547.jpg', '548.jpg', '549.jpg', '55.jpg', '550.jpg', '551.jpg', '552.jpg', '553.jpg', '554.jpg', '555.jpg', '556.jpg', '557.jpg', '558.jpg', '559.jpg', '56.jpg', '560.jpg', '561.jpg', '562.jpg', '563.jpg', '564.jpg', '565.jpg', '566.jpg', '567.jpg', '568.jpg', '569.jpg', '57.jpg', '570.jpg', '571.jpg', '572.jpg', '573.jpg', '574.jpg', '575.jpg', '576.jpg', '577.jpg', '578.jpg', '579.jpg', '58.jpg', '580.jpg', '581.jpg', '582.jpg', '583.jpg', '584.jpg', '585.jpg', '586.jpg', '587.jpg', '588.jpg', '589.jpg', '59.jpg', '590.jpg', '591.jpg', '592.jpg', '593.jpg', '594.jpg', '595.jpg', '596.jpg', '597.jpg', '598.jpg', '599.jpg', '6.jpg', '60.jpg', '600.jpg', '601.jpg', '602.jpg', '603.jpg', '604.jpg', '605.jpg', '606.jpg', '607.jpg', '608.jpg', '609.jpg', '61.jpg', '610.jpg', '611.jpg', '612.jpg', '613.jpg', '614.jpg', '615.jpg', '616.jpg', '617.jpg', '618.jpg', '619.jpg', '62.jpg', '620.jpg', '621.jpg', '622.jpg', '623.jpg', '624.jpg', '625.jpg', '626.jpg', '627.jpg', '628.jpg', '629.jpg', '63.jpg', '630.jpg', '631.jpg', '632.jpg', '633.jpg', '634.jpg', '635.jpg', '636.jpg', '637.jpg', '638.jpg', '639.jpg', '64.jpg', '640.jpg', '641.jpg', '642.jpg', '643.jpg', '644.jpg', '645.jpg', '646.jpg', '647.jpg', '648.jpg', '649.jpg', '65.jpg', '650.jpg', '651.jpg', '652.jpg', '653.jpg', '654.jpg', '655.jpg', '656.jpg', '657.jpg', '658.jpg', '659.jpg', '66.jpg', '660.jpg', '661.jpg', '662.jpg', '663.jpg', '664.jpg', '665.jpg', '666.jpg', '667.jpg', '668.jpg', '669.jpg', '67.jpg', '670.jpg', '671.jpg', '672.jpg', '673.jpg', '674.jpg', '675.jpg', '676.jpg', '677.jpg', '678.jpg', '679.jpg', '68.jpg', '680.jpg', '681.jpg', '682.jpg', '683.jpg', '684.jpg', '685.jpg', '686.jpg', '687.jpg', '688.jpg', '689.jpg', '69.jpg', '690.jpg', '691.jpg', '692.jpg', '693.jpg', '694.jpg', '695.jpg', '696.jpg', '697.jpg', '698.jpg', '699.jpg', '7.jpg', '70.jpg', '700.jpg', '701.jpg', '702.jpg', '703.jpg', '704.jpg', '705.jpg', '706.jpg', '707.jpg', '708.jpg', '709.jpg', '71.jpg', '710.jpg', '711.jpg', '712.jpg', '713.jpg', '714.jpg', '715.jpg', '716.jpg', '717.jpg', '718.jpg', '719.jpg', '72.jpg', '720.jpg', '721.jpg', '722.jpg', '723.jpg', '724.jpg', '725.jpg', '726.jpg', '727.jpg', '728.jpg', '729.jpg', '73.jpg', '730.jpg', '731.jpg', '732.jpg', '733.jpg', '734.jpg', '735.jpg', '736.jpg', '737.jpg', '738.jpg', '739.jpg', '74.jpg', '740.jpg', '741.jpg', '742.jpg', '743.jpg', '744.jpg', '745.jpg', '746.jpg', '747.jpg', '748.jpg', '749.jpg', '75.jpg', '750.jpg', '751.jpg', '752.jpg', '753.jpg', '754.jpg', '755.jpg', '756.jpg', '757.jpg', '758.jpg', '759.jpg', '76.jpg', '760.jpg', '761.jpg', '762.jpg', '763.jpg', '764.jpg', '765.jpg', '766.jpg', '767.jpg', '768.jpg', '769.jpg', '77.jpg', '770.jpg', '771.jpg', '772.jpg', '773.jpg', '774.jpg', '775.jpg', '776.jpg', '777.jpg', '778.jpg', '779.jpg', '78.jpg', '780.jpg', '781.jpg', '782.jpg', '783.jpg', '784.jpg', '785.jpg', '786.jpg', '787.jpg', '788.jpg', '789.jpg', '79.jpg', '790.jpg', '791.jpg', '792.jpg', '793.jpg', '794.jpg', '795.jpg', '796.jpg', '797.jpg', '798.jpg', '799.jpg', '8.jpg', '80.jpg', '800.jpg', '801.jpg', '802.jpg', '803.jpg', '804.jpg', '805.jpg', '806.jpg', '807.jpg', '808.jpg', '809.jpg', '81.jpg', '810.jpg', '811.jpg', '812.jpg', '813.jpg', '814.jpg', '815.jpg', '816.jpg', '817.jpg', '818.jpg', '819.jpg', '82.jpg', '820.jpg', '821.jpg', '822.jpg', '823.jpg', '824.jpg', '825.jpg', '826.jpg', '827.jpg', '828.jpg', '829.jpg', '83.jpg', '830.jpg', '831.jpg', '832.jpg', '833.jpg', '834.jpg', '835.jpg', '836.jpg', '837.jpg', '838.jpg', '839.jpg', '84.jpg', '840.jpg', '841.jpg', '842.jpg', '843.jpg', '844.jpg', '845.jpg', '846.jpg', '847.jpg', '848.jpg', '849.jpg', '85.jpg', '850.jpg', '851.jpg', '852.jpg', '853.jpg', '854.jpg', '855.jpg', '856.jpg', '857.jpg', '858.jpg', '859.jpg', '86.jpg', '860.jpg', '861.jpg', '862.jpg', '863.jpg', '864.jpg', '865.jpg', '866.jpg', '867.jpg', '868.jpg', '869.jpg', '87.jpg', '870.jpg', '871.jpg', '872.jpg', '873.jpg', '874.jpg', '875.jpg', '876.jpg', '877.jpg', '878.jpg', '879.jpg', '88.jpg', '880.jpg', '881.jpg', '882.jpg', '883.jpg', '884.jpg', '885.jpg', '886.jpg', '887.jpg', '888.jpg', '889.jpg', '89.jpg', '890.jpg', '891.jpg', '892.jpg', '893.jpg', '894.jpg', '895.jpg', '896.jpg', '897.jpg', '898.jpg', '899.jpg', '9.jpg', '90.jpg', '900.jpg', '901.jpg', '902.jpg', '903.jpg', '904.jpg', '905.jpg', '906.jpg', '907.jpg', '908.jpg', '909.jpg', '91.jpg', '910.jpg', '911.jpg', '912.jpg', '913.jpg', '914.jpg', '915.jpg', '916.jpg', '917.jpg', '918.jpg', '919.jpg', '92.jpg', '920.jpg', '921.jpg', '922.jpg', '923.jpg', '924.jpg', '925.jpg', '926.jpg', '927.jpg', '928.jpg', '929.jpg', '93.jpg', '930.jpg', '931.jpg', '932.jpg', '933.jpg', '934.jpg', '935.jpg', '936.jpg', '937.jpg', '938.jpg', '939.jpg', '94.jpg', '940.jpg', '941.jpg', '942.jpg', '943.jpg', '944.jpg', '945.jpg', '946.jpg', '947.jpg', '948.jpg', '949.jpg', '95.jpg', '950.jpg', '951.jpg', '952.jpg', '953.jpg', '954.jpg', '955.jpg', '956.jpg', '957.jpg', '958.jpg', '959.jpg', '96.jpg', '960.jpg', '961.jpg', '962.jpg', '963.jpg', '964.jpg', '965.jpg', '966.jpg', '967.jpg', '968.jpg', '969.jpg', '97.jpg', '970.jpg', '971.jpg', '972.jpg', '973.jpg', '974.jpg', '975.jpg', '976.jpg', '977.jpg', '978.jpg', '979.jpg', '98.jpg', '980.jpg', '981.jpg', '982.jpg', '983.jpg', '984.jpg', '985.jpg', '986.jpg', '987.jpg', '988.jpg', '989.jpg', '99.jpg', '990.jpg', '991.jpg', '992.jpg', '993.jpg', '994.jpg', '995.jpg', '996.jpg', '997.jpg', '998.jpg', '999.jpg']\n",
      "torch.Size([5, 3, 256, 256])\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/edgar/ml/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3707: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "class MapDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.list_files = os.listdir(self.root_dir)\n",
    "        #print(self.list_files)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.list_files)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_file = self.list_files[index]\n",
    "        img_path = os.path.join(self.root_dir, img_file)\n",
    "        image = np.array(Image.open(img_path))\n",
    "        input_image = image[:, :600, :] #images are 600x600 (so 1200 in width )\n",
    "        target_image = image[:, 600:, :]\n",
    "\n",
    "        augmentations = config.both_transform(image=input_image, image0=target_image)\n",
    "        input_image = augmentations[\"image\"]\n",
    "        target_image = augmentations[\"image0\"]\n",
    "\n",
    "        input_image = config.transform_only_input(image=input_image)[\"image\"]\n",
    "        target_image = config.transform_only_mask(image=target_image)[\"image\"]\n",
    "\n",
    "        return input_image, target_image\n",
    "    \n",
    "if __name__  == \"__main__\":\n",
    "    dataset = MapDataset(\"data/maps/train/\")\n",
    "    loader = DataLoader(dataset, batch_size = 5)\n",
    "    for x, y in loader: \n",
    "        print(x.shape)\n",
    "        save_image(x, \"x.png\")\n",
    "        save_image(y, \"y.png\")\n",
    "        import sympy\n",
    "        \n",
    "        sys.exit()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e44406",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#####train.py  \n",
    "\n",
    "#import torch \n",
    "from utils import save_checkpoint, load_checkpoint, save_some_examples\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "import config \n",
    "#from dataset import MapDataset\n",
    "#from generator_model import Generator\n",
    "#from discriminator_model import Discriminator \n",
    "from torch.utils.data import DataLoader \n",
    "from tqdm import tqdm\n",
    "from torchvision.utils import save_image \n",
    "\n",
    "def train_fn(disc, gen, opt_disc, opt_gen, l1, bce, g_scalar, d_scaler):\n",
    "    loop = tqdm(loader, leave=True)\n",
    "\n",
    "    for idx, (x, y) in enumerate(loop):\n",
    "        x, y = x.to(config.DEVICE), y.to(config.DEVICE)\n",
    "\n",
    "        #train the Discriminator\n",
    "        with torch.cuda.amp.autocast(): \n",
    "            y_fake = gen(x)\n",
    "            D_real = disc(x, y)\n",
    "            D_fake = disc(x, y_fake.detach())\n",
    "            D_real_loss = bce(D_real, torch.ones_like(D_real))\n",
    "            D_fake_loss = bce(D_fake, torch.zeros_like(D_fake))\n",
    "            D_loss = (D_real_loss + D_fake_loss) / 2\n",
    "        \n",
    "        disc.zero_grad()\n",
    "        d_scaler.scale(D_loss).backward()\n",
    "        d_scaler.step(opt_disc)\n",
    "        d_scaler.update()\n",
    "\n",
    "        #Train Generator \n",
    "        with torch.cuda.amp.autocast():\n",
    "            D_fake = disc(x, y_fake)\n",
    "            G_fake_loss = bce(D_fake, torch.ones_like(D_fake))\n",
    "            L1 = l1(y_fake, y)*config.L1_LAMBDA\n",
    "            G_loss = G_fake_loss + L1 \n",
    "\n",
    "        opt_gen.zero_grad()\n",
    "        g_scalar.scale(G_loss).backward()\n",
    "        g_scalar.step(opt_gen)\n",
    "        g_scalar.update()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def main():\n",
    "    disc = Discriminator(in_channels=3).to(config.DEVICE)\n",
    "    gen = Generator(in_channels=3).to(config.DEVICE)\n",
    "    opt_disc = optim.Adam(disc.parameters(), lr=config.LEARNING_RATE, betas=(0.5, 0.999))\n",
    "    opt_gen = optim.Adam(gen.parameters(), lr=config.LEARNING_RATE, betas=(0.5, 0.999))\n",
    "    BCE = nn.BCEWithLogitsLoss()\n",
    "    L1_LOSS = nn.L1Loss()\n",
    "\n",
    "    if config.LOAD_MODEL: \n",
    "        load_checkpoint(config.CHECKPOINT_GEN, gen, opt_gen, config.LEARNING_RATE)\n",
    "        load_checkpoint(config.CHECKPOINT_DISC, disc, opt_disc, config.LEARNING_RATE)\n",
    "\n",
    "    train_dataset = MapDataset(root_dir=\"data/maps/train\")\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True, num_workers=config.NUM_WORKERS)\n",
    "    g_scalar = torch.cuda.amp.GradScaler()\n",
    "    d_scalar = torch.cuda.amp.GradScaler()\n",
    "    val_dataset = MapDataset(root_dir=\"data/maps/val\")\n",
    "    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    for epoch in range(config.NUM_EPOCHS):\n",
    "        train_fn(disc, gen, train_loader, opt_gen, L1_LOSS, BCE, g_scalar, d_scalar)\n",
    "\n",
    "        if config.SAVE_MODEL and epoch % 5 == 0:\n",
    "            save_checkpoint(gen, opt_gen, filename=config.CHECKPOINT_GEN)\n",
    "            save_checkpoint(disc, opt_disc, filename=config.CHECKPOINT_DISC)\n",
    "\n",
    "        \n",
    "        save_some_examples(gen, val_loader, epoch, folder=\"evaluation\")\n",
    "\n",
    "\n",
    "\n",
    "if __name__ ==  \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
